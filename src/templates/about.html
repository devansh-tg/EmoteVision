<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About ‚Äî EmoteVision</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=Space+Grotesk:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
</head>
<body>

<!-- Particle canvas (neural network background) -->
<canvas id="particle-canvas"></canvas>

<!-- Ambient colour blobs -->
<div class="bg-blobs" aria-hidden="true">
    <div class="blob blob-1"></div>
    <div class="blob blob-2"></div>
    <div class="blob blob-3"></div>
</div>

<div class="page-wrapper">

    <!-- Header -->
    <header class="header">
        <div class="container">
            <h1 class="logo">üé≠ EmoteVision</h1>
            <nav>
                <a href="/" class="nav-link">Home</a>
                <a href="/about" class="nav-link active">About</a>
                <a href="https://github.com/devansh-tg/emojify--copy-" target="_blank" class="nav-link">GitHub</a>
            </nav>
        </div>
    </header>

    <!-- Main Content -->
    <main class="main-content">
        <div class="container">
            <div class="about-section">
                <h2 class="page-title">About This Project</h2>
                
                <div class="card about-card">
                    <h3>üéØ Project Overview</h3>
                    <p>This is an AI-powered real-time emotion detection system that uses Deep Learning to classify facial expressions into 7 different emotions: Angry, Disgust, Fear, Happy, Neutral, Sad, and Surprise.</p>
                </div>

                <div class="card about-card">
                    <h3>üß† Technology Stack</h3>
                    <ul class="tech-list">
                        <li><strong>Backend:</strong> Flask + Flask-SocketIO (Python)</li>
                        <li><strong>Real-time Transport:</strong> WebSocket via Socket.IO (replaces HTTP polling)</li>
                        <li><strong>Deep Learning:</strong> TensorFlow / Keras + optional TFLite runtime</li>
                        <li><strong>Face Detection:</strong> MediaPipe BlazeFace (preferred) with Haar Cascade fallback</li>
                        <li><strong>Computer Vision:</strong> OpenCV</li>
                        <li><strong>Frontend:</strong> HTML5, CSS3, JavaScript + Chart.js for live trend charts</li>
                        <li><strong>Model:</strong> Custom CNN (4 convolutional blocks)</li>
                    </ul>
                </div>

                <div class="card about-card">
                    <h3>üìä Model Architecture</h3>
                    <ul class="tech-list">
                        <li><strong>Input:</strong> 48x48 grayscale images</li>
                        <li><strong>Architecture:</strong> 4 Convolutional blocks with BatchNormalization</li>
                        <li><strong>Parameters:</strong> ~2.7
                             million trainable parameters</li>
                        <li><strong>Training:</strong> 150 epochs with early stopping</li>
                        <li><strong>Platform:</strong> Kaggle GPU (T4 x2)</li>
                        <li><strong>Dataset:</strong> 35,000+ facial expression images</li>
                        <li><strong>Accuracy:</strong> 70.01% (Good for 7-class classification)</li>
                    </ul>
                </div>

                <div class="card about-card">
                    <h3>‚ú® Features</h3>
                    <ul class="tech-list">
                        <li>Real-time emotion detection via WebSocket push (no polling)</li>
                        <li>Multi-face detection ‚Äî all faces processed per frame</li>
                        <li>Live Chart.js trend graph ‚Äî 7-class probability over 60 seconds</li>
                        <li>Engagement Score ‚Äî weighted metric combining all emotion signals</li>
                        <li>EWA temporal smoothing ‚Äî eliminates emotion flicker between frames</li>
                        <li>Session export ‚Äî download emotion log as CSV</li>
                        <li>Dark / Light theme toggle with localStorage persistence</li>
                        <li>REST API endpoints for external integrations</li>
                        <li>TFLite runtime support for 3-5√ó faster CPU inference</li>
                    </ul>
                </div>

                <div class="card about-card">
                    <h3>üöÄ How It Works</h3>
                    <ol class="tech-list">
                        <li>A background thread continuously reads frames from the camera into a shared FrameBuffer</li>
                        <li>MediaPipe BlazeFace (or Haar Cascade fallback) detects all faces per frame</li>
                        <li>Each face ROI is extracted, resized to 48√ó48 grayscale, and normalised</li>
                        <li>CNN (or TFLite) model predicts a 7-class probability vector per face</li>
                        <li>EWA temporal smoothing is applied to the primary face to reduce flicker</li>
                        <li>Results are pushed to all browser clients instantly via Socket.IO WebSocket</li>
                        <li>Chart.js renders a live sliding trend graph; engagement score is updated in real time</li>
                    </ol>
                </div>

                <div class="card about-card">
                    <h3>üìà Performance</h3>
                    <ul class="tech-list">
                        <li><strong>Inference Speed:</strong> 20-60ms per prediction</li>
                        <li><strong>Real-time FPS:</strong> 25-35 frames per second</li>
                        <li><strong>Model Size:</strong> ~31.4 MB</li>
                        <li><strong>Accuracy:</strong> 70.01% (7-class classification)</li>
                    </ul>
                </div>

                <div class="card about-card">
                    <h3>üë®‚Äçüíª Developer</h3>
                    <p>Built by <strong>Devansh Tyagi</strong></p>
                    <p>GitHub: <a href="https://github.com/devansh-tg" target="_blank">@devansh-tg</a></p>
                    <p>Repository: <a href="https://github.com/devansh-tg/emojify--copy-" target="_blank">emojify--copy-</a></p>
                </div>

                <div style="text-align:center;margin-top:32px">
                    <a href="/" class="back-button">‚Üê Back to Detection</a>
                </div>
            </div>
        </div>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2026 EmoteVision | Built with TensorFlow, Flask-SocketIO &amp; Chart.js</p>
        </div>
    </footer>

</div><!-- /.page-wrapper -->

<script>
// Minimal particle + theme init for about page
(function(){
    const saved = localStorage.getItem('emotevision-theme') || 'dark';
    document.documentElement.setAttribute('data-theme', saved);

    // Particles
    const cvs = document.getElementById('particle-canvas');
    if (!cvs) return;
    const ctx = cvs.getContext('2d');
    let w, h;
    const COUNT = 40;
    const LINK = 130;
    function resize() { w = cvs.width = innerWidth; h = cvs.height = innerHeight; }
    resize(); addEventListener('resize', resize);
    class P {
        constructor() { this.x=Math.random()*w; this.y=Math.random()*h; this.vx=(Math.random()-.5)*.4; this.vy=(Math.random()-.5)*.4; this.r=Math.random()*2+1; }
        update() { this.x+=this.vx; this.y+=this.vy; if(this.x<0||this.x>w)this.vx*=-1; if(this.y<0||this.y>h)this.vy*=-1; }
    }
    const ps = Array.from({length:COUNT}, ()=>new P());
    (function frame(){
        ctx.clearRect(0,0,w,h);
        for(let i=0;i<COUNT;i++) for(let j=i+1;j<COUNT;j++){
            const dx=ps[i].x-ps[j].x, dy=ps[i].y-ps[j].y, d=Math.sqrt(dx*dx+dy*dy);
            if(d<LINK){ctx.beginPath();ctx.moveTo(ps[i].x,ps[i].y);ctx.lineTo(ps[j].x,ps[j].y);ctx.strokeStyle=`rgba(0,212,255,${((1-d/LINK)*.2).toFixed(3)})`;ctx.lineWidth=.5;ctx.stroke();}
        }
        for(const p of ps){p.update();ctx.beginPath();ctx.arc(p.x,p.y,p.r,0,Math.PI*2);ctx.fillStyle='rgba(0,212,255,.35)';ctx.fill();}
        requestAnimationFrame(frame);
    })();
})();
</script>
</body>
</html>
